{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MARBLE and Cebra\n",
    "\n",
    "In this notebook we train the MARBLE and Cebra models to analyse the rat hippocampal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/honglab/leijiaxin/anaconda3/envs/MARBLE/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ! pip install cebra elephant\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from cebra import CEBRA\n",
    "\n",
    "import MARBLE\n",
    "from rat_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-07 15:46:04--  https://dataverse.harvard.edu/api/access/datafile/7609512\n",
      "Resolving dataverse.harvard.edu (dataverse.harvard.edu)... 3.227.129.123, 44.208.2.139, 3.209.13.112\n",
      "Connecting to dataverse.harvard.edu (dataverse.harvard.edu)|3.227.129.123|:443... connected.\n",
      "HTTP request sent, awaiting response... 202 Accepted\n",
      "Length: 0 [text/html]\n",
      "Saving to: ‘data/rat_data.pkl’\n",
      "\n",
      "data/rat_data.pkl       [ <=>                ]       0  --.-KB/s    in 0s      \n",
      "\n",
      "2025-03-07 15:46:05 (0.00 B/s) - ‘data/rat_data.pkl’ saved [0/0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "# !wget -nc https://dataverse.harvard.edu/api/access/datafile/7609512 -O data/rat_data.pkl\n",
    "\n",
    "# with open('data/rat_data.pkl', 'rb') as handle:\n",
    "#     hippocampus_pos = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "\n",
    "*[This can be skipped if you already saved the models].*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hippocampus_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m     label_test \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinuous_index\u001b[39m\u001b[38;5;124m'\u001b[39m][split_idx:]\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m neural_train\u001b[38;5;241m.\u001b[39mnumpy(), neural_test\u001b[38;5;241m.\u001b[39mnumpy(), label_train\u001b[38;5;241m.\u001b[39mnumpy(), label_test\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 14\u001b[0m neural_train, neural_test, label_train, label_test \u001b[38;5;241m=\u001b[39m split_data(\u001b[43mhippocampus_pos\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124machilles\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hippocampus_pos' is not defined"
     ]
    }
   ],
   "source": [
    "# defining train and test splits of the data\n",
    "\n",
    "def split_data(data, test_ratio):\n",
    "\n",
    "    split_idx = int(data['neural'].shape[0] * (1-test_ratio))\n",
    "    neural_train = data['neural'][:split_idx]\n",
    "    neural_test = data['neural'][split_idx:]\n",
    "    label_train = data['continuous_index'][:split_idx]\n",
    "    label_test = data['continuous_index'][split_idx:]\n",
    "    \n",
    "    return neural_train.numpy(), neural_test.numpy(), label_train.numpy(), label_test.numpy()\n",
    "\n",
    "\n",
    "neural_train, neural_test, label_train, label_test = split_data(hippocampus_pos['achilles'], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 hz sampling rate (they binned into 25ms epochs\n",
    "\n",
    "spikes = neural_train[:2000,:].T\n",
    "spikes = [np.where(spikes[ch,:])[0]/40 for ch in range(120)] \n",
    "    \n",
    "_, ax = plt.subplots(figsize=(8,4))\n",
    "ax.eventplot(spikes,color='gray')\n",
    "plt.ylabel('Neurons')\n",
    "plt.xlabel('Time (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CEBRA-time and Cebra-behaviour on all animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10000\n",
    "output_dimension = 32 #set to 3 for embeddings and 32 for decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for rat in list(hippocampus_pos.keys()):\n",
    "\n",
    "    print('train Cebra time')\n",
    "    cebra_time = CEBRA(model_architecture='offset10-model',\n",
    "                       batch_size=512,\n",
    "                       learning_rate=3e-4,\n",
    "                       temperature=1.12,\n",
    "                       output_dimension=output_dimension,\n",
    "                       max_iterations=10000,\n",
    "                       distance='cosine',\n",
    "                       conditional='time', # 'time' means we are only using time information in the samples\n",
    "                       device='cuda_if_available',\n",
    "                       verbose=True,\n",
    "                       time_offsets=10)\n",
    "    \n",
    "    cebra_time.fit(hippocampus_pos[rat][\"neural\"])\n",
    "    cebra_time.save(f\"data/cebra_time_{rat}.pt\")\n",
    "\n",
    "    print('train Cebra behaviour')\n",
    "    cebra_behaviour = CEBRA(model_architecture='offset10-model',\n",
    "                            batch_size=512,\n",
    "                            learning_rate=3e-4,\n",
    "                            temperature=1,\n",
    "                            output_dimension=output_dimension, \n",
    "                            max_iterations=max_iterations,\n",
    "                            distance='cosine',\n",
    "                            conditional='time_delta', #'time_delta' means we will use CEBRA-Behavior mode and use auxiliary behavior variable for the model training\n",
    "                            device='cuda_if_available',\n",
    "                            verbose=True,\n",
    "                            time_offsets=10)\n",
    "    \n",
    "    cebra_behaviour.fit(hippocampus_pos[rat][\"neural\"], hippocampus_pos[rat]['continuous_index'].numpy())\n",
    "    cebra_behaviour.save(f\"data/cebra_behaviour_{rat}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MARBLE with only neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rat in list(hippocampus_pos.keys()):\n",
    "    # build model \n",
    "    data, labels, _ = convert_spikes_to_rates(hippocampus_pos[rat][\"neural\"],\n",
    "                                              labels=hippocampus_pos[rat]['continuous_index'].numpy(),\n",
    "                                              pca_n=10)\n",
    "    pickle.dump([data, labels], open(f'data/{rat}_preprocessed_data.pkl','wb'))\n",
    "    \n",
    "    # build model\n",
    "    params = {\n",
    "        \"epochs\": 100,\n",
    "        \"order\": 1,  # order of derivatives\n",
    "        \"hidden_channels\": [64],  # number of internal dimensions in MLP\n",
    "        \"out_channels\": output_dimension, \n",
    "        \"inner_product_features\": False,\n",
    "        \"emb_norm\": True, # spherical output embedding\n",
    "        \"diffusion\": False,\n",
    "        \"include_positions\": True,\n",
    "      }\n",
    "    \n",
    "    model = MARBLE.net(data, params=params.copy()) #define model\n",
    "    model.fit(data, outdir=f\"data/hippocampus_{rat}\") # train model\n",
    "    data = model.transform(data) #evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MARBLE with different preprocessing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary PCA dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"epochs\": 100,\n",
    "        \"order\": 1,  # order of derivatives\n",
    "        \"hidden_channels\": [64],  # number of internal dimensions in MLP\n",
    "        \"out_channels\": 32, \n",
    "        \"inner_product_features\": False,\n",
    "        \"emb_norm\": True, # spherical output embedding\n",
    "        \"diffusion\": False,\n",
    "        \"include_positions\": True,\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rat = 'achilles'\n",
    "kernel_width = 10\n",
    "\n",
    "for pca_n in [3,5,10,20,30]:\n",
    "\n",
    "    data, _, _ = convert_spikes_to_rates(hippocampus_pos[rat][\"neural\"],\n",
    "                                        pca_n=pca_n,\n",
    "                                        kernel_width=kernel_width)\n",
    "    model = MARBLE.net(data, params=params.copy())\n",
    "    model.fit(data, outdir=f\"data/hippocampus_{rat}_pca{pca_n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary Gaussian kernel width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_n = 20\n",
    "rat = 'achilles'\n",
    "\n",
    "for kernel_width in [3,5,10,20,30,50,100]:\n",
    "    data, _, _ = convert_spikes_to_rates(hippocampus_pos[rat][\"neural\"], \n",
    "                                         pca_n=pca_n,\n",
    "                                         kernel_width=kernel_width)\n",
    "    model = MARBLE.net(data, params=params.copy())\n",
    "    model.fit(data, outdir=f\"data/hippocampus_{rat}_kw{kernel_width}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MARBLE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
